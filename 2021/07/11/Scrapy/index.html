<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Scrapy | JOEL-T99</title><meta name="keywords" content="Python - Scrapy"><meta name="author" content="JOEL-T99"><meta name="copyright" content="JOEL-T99"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="Scrapy使用步骤：  创建爬虫项目：scrapy startproject xxx 创建爬虫文件：scrapy genspider xxx（爬虫名） xxx.com （爬取域） 定义要爬取的内容：修改 item.py 文件 定义如何爬取内容：编写爬取网站的 spider 并读取 Item 存取爬取到的信息：编写 Item Pipeline 来存储提取的 Item（及数据） 运行爬虫：scrap">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy">
<meta property="og:url" content="http://yoursite.com/2021/07/11/Scrapy/index.html">
<meta property="og:site_name" content="JOEL-T99">
<meta property="og:description" content="Scrapy使用步骤：  创建爬虫项目：scrapy startproject xxx 创建爬虫文件：scrapy genspider xxx（爬虫名） xxx.com （爬取域） 定义要爬取的内容：修改 item.py 文件 定义如何爬取内容：编写爬取网站的 spider 并读取 Item 存取爬取到的信息：编写 Item Pipeline 来存储提取的 Item（及数据） 运行爬虫：scrap">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg">
<meta property="article:published_time" content="2021-07-11T13:11:34.000Z">
<meta property="article:modified_time" content="2021-07-11T13:13:27.285Z">
<meta property="article:author" content="JOEL-T99">
<meta property="article:tag" content="Python - Scrapy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg"><link rel="shortcut icon" href="/img/fav.ico"><link rel="canonical" href="http://yoursite.com/2021/07/11/Scrapy/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#00c4b6","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-07-11 21:13:27'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="JOEL-T99" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/background.jpg" onerror="onerror=null;src='/img/touxiang.png'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">57</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">JOEL-T99</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">Scrapy</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-07-11T13:11:34.000Z" title="Created 2021-07-11 21:11:34">2021-07-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-07-11T13:13:27.285Z" title="Updated 2021-07-11 21:13:27">2021-07-11</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/2021/07/11/Scrapy/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2021/07/11/Scrapy/" itemprop="commentCount"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h1><p>使用步骤：</p>
<ol>
<li>创建爬虫项目：<code>scrapy startproject xxx</code></li>
<li>创建爬虫文件：<code>scrapy genspider xxx</code>（爬虫名） <code>xxx.com</code> （爬取域）</li>
<li>定义要爬取的内容：修改 <code>item.py</code> 文件</li>
<li>定义如何爬取内容：编写爬取网站的 spider 并读取 Item</li>
<li>存取爬取到的信息：编写 Item Pipeline 来存储提取的 Item（及数据）</li>
<li>运行爬虫：<code>scrapy crawl xxx</code></li>
</ol>
<h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><p>以Anaconda为例，打开Anaconda Prompt，创建项目的命令：<code>scrapt startproject test01</code></p>
<p>项目所包含的文件：</p>
<p><code>test01/</code>：此目录为创建项目的python模块，爬取代码在此目录下填写</p>
<p><code>test01/spiders/</code>：此目录为放置spider的位置，该位置包含Scrapy项目的爬虫器</p>
<p><code>test01/items.py</code>：该项目的item文件</p>
<p><code>test01/middlewares.py</code>：在这里为爬行器中间件定义模型</p>
<p><code>test01/pipelines.py</code>：在这里定义项目管道</p>
<p><code>test01/settings.py</code>：该项目的Scrapy设置文件[]</p>
<h1 id="创建爬虫文件"><a href="#创建爬虫文件" class="headerlink" title="创建爬虫文件"></a>创建爬虫文件</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider price price.com</span><br></pre></td></tr></table></figure>

<p>执行完 <code>scrapy genspider</code> 命令后会在项目的 spiders 目录下生成一个名为 price.py 的爬虫文件。也可使用PyCharm 创建。</p>
<h1 id="定义要爬取的内容"><a href="#定义要爬取的内容" class="headerlink" title="定义要爬取的内容"></a>定义要爬取的内容</h1><p>Item为所爬取数据的容器，类似字典方法的运用，但同时提供了额外保护机制来避免拼写错误导致的未定义字段错误。</p>
<p>在项目文件中的 <code>items.py</code> 文件中，通过创建一个 <code>scrapy.Item</code> 类，可以定义类型为 <code>scrapy.Field</code> 的类属性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scrapytest01Item</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    name = scrapy.Field()      <span class="comment">#楼盘名称</span></span><br><span class="line">    district = scrapy.Field()  <span class="comment">#所属城区</span></span><br><span class="line">    loc = scrapy.Field()	   <span class="comment">#详细地址</span></span><br><span class="line">    area = scrapy.Field()      <span class="comment">#建面</span></span><br><span class="line">    price = scrapy.Field()	   <span class="comment">#价格</span></span><br><span class="line">    danwei = scrapy.Field()    <span class="comment">#单位</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>



<h1 id="定义如何爬取内容"><a href="#定义如何爬取内容" class="headerlink" title="定义如何爬取内容"></a>定义如何爬取内容</h1><p>Spider可用于从单个网站（或一些网站）爬取数据的类。</p>
<p>在项目文件中的 <code>spider</code> 目录中创建一个Spider，同时需要继承 <code>scrapy.Spider</code> 类。</p>
<p>需要定义的三个属性如下：</p>
<ol>
<li><code>name</code>：用于区别Spider，该名称必须是唯一的。</li>
<li><code>start_urls</code>：此处包含需要爬取的URL链接地址，以列表的方式放入。第一个URL相当于根页面，后续的URL链接则从这个初始的URL中获取数据。</li>
<li><code>parse()</code>：是spider的一个方法。当被调用时，每个初始URL完成下载后生成的 response 对象，将会作为唯一的参数传递给改该函数。该方法负责解析并返回的数据（response data），提取数据（生成item）以及生成进一步处理的URL的 response 对象。</li>
</ol>
<h2 id="提取Item"><a href="#提取Item" class="headerlink" title="提取Item"></a>提取Item</h2><p>Scrapy使用的一种基于 XPath 和 CSS 表达式机制：<code>Scrapy Selectors</code></p>
<p>XPath是一门在XML文档中查找信息的语言，使用路径表达式来选取XML文档中的结点或者节点集。</p>
<table>
<thead>
<tr>
<th>表达式</th>
<th>含义</th>
<th>表达式</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>//nodename/*</code></td>
<td>选取此节点的所有子节点</td>
<td><code>.</code></td>
<td>选取当前节点</td>
</tr>
<tr>
<td><code>/</code></td>
<td>从根节点选取</td>
<td><code>..</code></td>
<td>选取当前节点的父节点</td>
</tr>
<tr>
<td><code>//</code></td>
<td>选择任意位置的某个节点</td>
<td><code>@</code></td>
<td></td>
</tr>
</tbody></table>
<p>链接：<a target="_blank" rel="noopener" href="https://hz.focus.cn/loupan/">https://hz.focus.cn/loupan/</a></p>
<p>使用Chrome浏览器，在任意处右键点击检查，选择 Elements ，可以看到每块信息被存放在 class 名为 <code>s-lp-all</code>  的 div 中。</p>
<p>因此我们需要选择页面的所有房源信息，可以通过 XPath 表达式实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">base_url = <span class="string">&#x27;https://hz.focus.cn/loupan/p&#x27;</span></span><br><span class="line">house_list = response.xpath(<span class="string">&#x27;//div[@class=&quot;s-lp-all&quot;]&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p>通过对 Elements 的查看，我们发现所需的楼盘信息被存放在各自的 div 中。</p>
<ol>
<li>楼盘名称：存放在 class 名为 title 的 div 中</li>
<li>所属城区+详细地址：存放在 class 名为 location 的 div 中</li>
<li>建面：存放在 class 名为 building-area 的 span 中</li>
<li>价格：存放在 class 名为 price 的 span 中</li>
<li>单位：存放在 class 名为 danwei 的 span 中</li>
</ol>
<p>以此可以得出提取信息的表达式为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = each.xpath(<span class="string">&#x27;.//div[@class=&quot;title&quot;]/a/text()&#x27;</span>).extract()</span><br><span class="line">loc = each.xpath(<span class="string">&#x27;.//p[@class=&quot;location&quot;]/span/text()&#x27;</span>).extract()</span><br><span class="line">area = each.xpath(<span class="string">&#x27;.//span[@class=&quot;building-area&quot;]/text()&#x27;</span>).extract()</span><br><span class="line">price = each.xpath(<span class="string">&#x27;.//span[@class=&quot;price&quot;]/text()&#x27;</span>).extract()</span><br><span class="line">danwei = each.xpath(<span class="string">&#x27;.//span[@class=&quot;danwei&quot;]/text()&#x27;</span>).extract()</span><br></pre></td></tr></table></figure>



<p>实现爬取多页信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">25</span>):</span><br><span class="line">	url_ = <span class="string">&#x27;&#x27;</span>.join([base_url,<span class="built_in">str</span>(page), <span class="string">&#x27;/&#x27;</span>])</span><br><span class="line">	next_request = Request(url_, callback=self.parse)</span><br><span class="line">	<span class="keyword">yield</span> next_request</span><br></pre></td></tr></table></figure>



<p>在项目文件中的 <code>spider</code> 目录中创建一个 <code>price.py</code>  文件，并将以上的信息整理放入，注意导包。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapytest01.items <span class="keyword">import</span> HangzhouHouseItem</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PriceSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;price&#x27;</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://hz.focus.cn/loupan/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        base_url = <span class="string">&#x27;https://hz.focus.cn/loupan/p&#x27;</span></span><br><span class="line">        house_list = response.xpath(<span class="string">&#x27;//div[@class=&quot;s-lp-all &quot;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> house_list:</span><br><span class="line">            item = HangzhouHouseItem()</span><br><span class="line">            name = each.xpath(<span class="string">&#x27;.//div[@class=&quot;title&quot;]/a/text()&#x27;</span>).extract()</span><br><span class="line">            loc = each.xpath(<span class="string">&#x27;.//p[@class=&quot;location&quot;]/span/text()&#x27;</span>).extract()</span><br><span class="line">            area = each.xpath(<span class="string">&#x27;.//span[@class=&quot;building-area&quot;]/text()&#x27;</span>).extract()</span><br><span class="line">            price = each.xpath(<span class="string">&#x27;.//span[@class=&quot;price&quot;]/text()&#x27;</span>).extract()</span><br><span class="line">            danwei = each.xpath(<span class="string">&#x27;.//span[@class=&quot;danwei&quot;]/text()&#x27;</span>).extract()</span><br><span class="line"></span><br><span class="line">            item[<span class="string">&#x27;name&#x27;</span>] = name[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">&#x27;loc&#x27;</span>] = loc[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">&#x27;area&#x27;</span>] = area[<span class="number">0</span>] <span class="keyword">if</span> area <span class="keyword">else</span> <span class="string">&#x27;NAN&#x27;</span></span><br><span class="line">            item[<span class="string">&#x27;price&#x27;</span>] = price[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">&#x27;danwei&#x27;</span>] = danwei[<span class="number">0</span>] <span class="keyword">if</span> danwei <span class="keyword">else</span> <span class="string">&#x27;NAN&#x27;</span></span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">25</span>):</span><br><span class="line">            url_ = <span class="string">&#x27;&#x27;</span>.join([base_url, <span class="built_in">str</span>(page), <span class="string">&#x27;/&#x27;</span>])</span><br><span class="line">            next_request = Request(url_, callback=self.parse)</span><br><span class="line">            <span class="keyword">yield</span> next_request</span><br></pre></td></tr></table></figure>



<h1 id="存取爬取到的信息"><a href="#存取爬取到的信息" class="headerlink" title="存取爬取到的信息"></a>存取爬取到的信息</h1><p>当一个项目爬取到数据后，数据被发送到项目管道，及工程目录下的 <code>pipelines.py</code> 文件，在此通过几个顺序执行的组件处理数据。</p>
<p>项目管道的典型用途是：</p>
<ol>
<li>清理HTML数据</li>
<li>验证抓取的数据（检查项目是否包含某些字段）</li>
<li>检查重复项（并删除他们）</li>
<li>将抓取的项目存储</li>
</ol>
<p>每个 item pipeline 组件是一个独立的Python类，同时必须实现以下方法：</p>
<ul>
<li><p><code>process_item(item,spider)</code></p>
<p>每个 item pipeline 组件都需要调用该方法，该方法必须返回一个 Item （或任何继承类）对象，或是抛出异常，被丢弃的 item 将不会被之后的 pipeline 组件所处理。</p>
<ul>
<li><p>参数：</p>
<p><code>item</code>：（Item 对象）被爬取的 item</p>
<p><code>spider</code>：（Spider 对象）爬取该 item 的 spider</p>
</li>
</ul>
</li>
</ul>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>通过 pipeline 将所有(从所有 spider中 )爬取到的 item，存储到一个独立的 CSV 或 JSON 文件，每行包含一个序列化为指定格式的 item。</p>
<p>在项目文件中的 <code>pipelines.py</code> 文件中，加入下方代码，注意导包。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HangzhouHousePipeline</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.file = <span class="built_in">open</span>(<span class="string">&#x27;../data.csv&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        self.csvwriter = csv.writer(self.file)</span><br><span class="line">        self.csvwriter.writerow([<span class="string">&#x27;名称&#x27;</span>, <span class="string">&#x27;地址&#x27;</span>, <span class="string">&#x27;建面&#x27;</span>, <span class="string">&#x27;价格&#x27;</span>, <span class="string">&#x27;单位&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        self.csvwriter.writerow([item[<span class="string">&quot;name&quot;</span>], item[<span class="string">&quot;loc&quot;</span>], item[<span class="string">&quot;area&quot;</span>], item[<span class="string">&quot;price&quot;</span>], item[<span class="string">&quot;danwei&quot;</span>]])</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure>





<hr>
<div align="center">❤️&nbspEND&nbsp❤️</div>

</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python-Scrapy/">Python - Scrapy</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付寶"/></a><div class="post-qr-code-desc">支付寶</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/07/11/XPath/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">XPath</div></div></a></div><div class="next-post pull-right"><a href="/2021/06/19/Pandas-%E5%9F%BA%E7%A1%80/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="onerror=null;src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Pandas 基础</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/background.jpg" onerror="this.onerror=null;this.src='/img/touxiang.png'" alt="avatar"/><div class="author-info__name">JOEL-T99</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">57</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/JOEL-T99"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/JOEL-T99" target="_blank" title="Github"><i class="fa fa-github"></i></a><a class="social-icon" href="mailto:t1141815771@yeah.net" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">感谢访问本站，若喜欢请收藏 ^_^</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy"><span class="toc-number">1.</span> <span class="toc-text">Scrapy</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">2.</span> <span class="toc-text">创建项目</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB%E6%96%87%E4%BB%B6"><span class="toc-number">3.</span> <span class="toc-text">创建爬虫文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E8%A6%81%E7%88%AC%E5%8F%96%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-number">4.</span> <span class="toc-text">定义要爬取的内容</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%A6%82%E4%BD%95%E7%88%AC%E5%8F%96%E5%86%85%E5%AE%B9"><span class="toc-number">5.</span> <span class="toc-text">定义如何爬取内容</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E5%8F%96Item"><span class="toc-number">5.1.</span> <span class="toc-text">提取Item</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AD%98%E5%8F%96%E7%88%AC%E5%8F%96%E5%88%B0%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-number">6.</span> <span class="toc-text">存取爬取到的信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><span class="toc-number">6.1.</span> <span class="toc-text">数据存储</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/07/11/XPath/" title="XPath"><img src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'" alt="XPath"/></a><div class="content"><a class="title" href="/2021/07/11/XPath/" title="XPath">XPath</a><time datetime="2021-07-11T13:11:45.000Z" title="Created 2021-07-11 21:11:45">2021-07-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/07/11/Scrapy/" title="Scrapy"><img src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'" alt="Scrapy"/></a><div class="content"><a class="title" href="/2021/07/11/Scrapy/" title="Scrapy">Scrapy</a><time datetime="2021-07-11T13:11:34.000Z" title="Created 2021-07-11 21:11:34">2021-07-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/19/Pandas-%E5%9F%BA%E7%A1%80/" title="Pandas 基础"><img src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'" alt="Pandas 基础"/></a><div class="content"><a class="title" href="/2021/06/19/Pandas-%E5%9F%BA%E7%A1%80/" title="Pandas 基础">Pandas 基础</a><time datetime="2021-06-19T13:52:14.000Z" title="Created 2021-06-19 21:52:14">2021-06-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/15/Seaborn-%E6%B1%87%E6%80%BB/" title="Seaborn 汇总"><img src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'" alt="Seaborn 汇总"/></a><div class="content"><a class="title" href="/2021/06/15/Seaborn-%E6%B1%87%E6%80%BB/" title="Seaborn 汇总">Seaborn 汇总</a><time datetime="2021-06-15T04:02:01.000Z" title="Created 2021-06-15 12:02:01">2021-06-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/14/Seaborn-Multi-plot-grids/" title="Seaborn Multi-plot grids"><img src="https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/py.jpg" onerror="this.onerror=null;this.src='https://cdn.jsdelivr.net/gh/JOEL-T99/Pic//img/science.png'" alt="Seaborn Multi-plot grids"/></a><div class="content"><a class="title" href="/2021/06/14/Seaborn-Multi-plot-grids/" title="Seaborn Multi-plot grids">Seaborn Multi-plot grids</a><time datetime="2021-06-14T04:36:42.000Z" title="Created 2021-06-14 12:36:42">2021-06-14</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/index.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By JOEL-T99</div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="http://joel-t99.online/">Blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: '',
      appKey: '',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script></div></body></html>